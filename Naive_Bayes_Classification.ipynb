{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-C8omlh6Pq4"
      },
      "source": [
        "#Naive Bayes Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuqxFfyO6Pq6"
      },
      "source": [
        "# **Naive Bayes Classification**\n",
        "\n",
        "Here we will implement the Naive Bayes classification method and use it for SMS message classifcation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes model is a probabilistic classifier operating under the assumption that input data features are independent conditional on class assignment. We calculate prior probability of each class, $P(Y)$, and likelihoods, $P(X| Y)$, to determine posterior probability, $P(Y | X)$, using Bayesâ€™ Rule.\n"
      ],
      "metadata": {
        "id": "zfJ0jlf73l1L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io7R6hOn6Pq9"
      },
      "source": [
        "### Recap of the Naive Bayes Algorithm\n",
        "Naive Bayes classification is a fast and simple classification method. Its efficiency stems from some simplifications we make about the underlying probability distributions, namely, the assumption about the conditional independence of features. Suppose for any class $Y$, we have a probability distribution over all possible combinations of values for a feature vector $X$:\n",
        "$$\n",
        "P(X|Y).\n",
        "$$\n",
        "The main idea of Bayesian classification is to reverse the direction of dependence --- we want to predict the label based on the features:\n",
        "$$\n",
        "P(Y|X).\n",
        "$$\n",
        "This is made possible by the Bayes theorem:\n",
        "\\begin{equation}\n",
        "P(Y|X) = \\frac{P(X|Y)P(Y)}{P(X)}. \\tag{1}\n",
        "\\end{equation}\n",
        "\n",
        "To make it more concrete, let us consider the SMS message classification problem. Ignoring punctuations, each SMS message contains an ordered sequence of $T$ words (case-insensitive) $X = \\{X_1, ...,X_T\\}$. That is, $X$ corresponds to an SMS message, and $X_i$ corresponds to the $i$-th word in it. For each message from the training set, there is a corresponding label $Y\\in\\{spam, ham\\}$.\n",
        "\n",
        "**Model specification and key assumption.** The conditional distribution can be written as:\n",
        "$$\n",
        "P(X|Y) = P(X_1, ..., X_T|Y).\n",
        "$$\n",
        "Since this conditional probability is intractable, we simplify it in two steps:\n",
        "\n",
        "1. **Assume** that all features $X_i$ are independent, conditional on the category $Y$. This leads to a naive Bayes model which writes formally as\n",
        "\\begin{equation}\n",
        "P(X|Y) = P(X_1, ..., X_T|Y) = \\prod_{i=1}^T P(X_i|Y). \\tag{2}\n",
        "\\end{equation}\n",
        "\n",
        "2. **Assume** that $P(X_i | Y) = P(X_j|Y)$ for all $i \\neq j$.\n",
        "In other words, given the label $Y$, the value of the $7$-th word has the same distribution as the value of the $10$-th word. Note this is not assumed by default in naive Bayes, and we make this additional assumption to significantly simplify our model.\n",
        "It is often referred to as \"tying\" the probability $P(X_i|Y)$ over $i$.\n",
        "As a result, the order of words no longer matters for $P(X|Y)$,\n",
        "i.e.,\n",
        "$$P(X=\\text{'cat is cute'}|Y) \\ \\ = \\ \\ P(X=\\text{'cute cat is'}|Y) \\quad \\text{for all } Y.\n",
        "$$\n",
        "\n",
        "Plugging Eq (2) into the Bayes theorem in Eq (1), we arrive at\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(Y|X) &= \\frac{P(Y) P(X|Y)}{P(X)} = \\frac{P(Y)\\prod_{i=1}^T P(X_i|Y)}{P(X)} \\\\\n",
        "&\\propto P(Y)\\prod_{i=1}^T P(X_i|Y),\n",
        "\\end{aligned}\n",
        "$$\n",
        "where $\\propto$ denotes proportionality. Since the denominator $P(X)$ does not depend on $Y$, the prediction probability is proportional to the numerator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWSd8rJUqhZ7"
      },
      "source": [
        "**Making predictions.**\n",
        "Naturally, given an SMS message $X$, we can first compute $P(Y|X)$ for all possible categories $Y$ (in this example, only two categories), and then make predictions by outputting the $Y$ that maximizes the probability. This can be expressed mathmatically as:\n",
        "$$\n",
        "\\arg\\max_Y P(Y)\\prod_{i=1}^T P(X_i|Y) = \\arg\\max_Y \\left\\{\\log P(Y) + \\sum_{i=1}^T \\log P(X_i|Y) \\right\\}. \\tag{3}\n",
        "$$\n",
        "If there is a tie, we just break it arbitrarily.\n",
        "Here the logarithm uses natural basis.\n",
        "\n",
        "**Learning the model.**\n",
        "To apply the prediction rule in Eq (3), we need to first figure out (formally termed \"estimate\") the value of $P(Y)$ and $P(X_i|Y)$ by using the training data. Recall that since we tie the conditional probabilities $P(X_i|Y)$ across all $i$,\n",
        "the subscript $i$ can be dropped.\n",
        "However, we still carry it just for clarity.\n",
        "\n",
        "Firstly, $P(Y=y)$ can be estimated by computing the frequency of category $y$ in the whole training set ($y$ can be either \"$spam$\" or \"$ham$\"). Here, in order to avoid confusion, we have used the convention that capital letters denote random variables, and lowercase letters denote their possible instantiations.\n",
        "\n",
        "Secondly, $P(X_i = w |Y=y)$ for a word $w$ (e.g., \"cat\") can be estimated by counting the frequency that it appears in the training message set for a given category $y$:\n",
        "\\begin{align}\n",
        "P(X_i &= w|Y=y)\n",
        "= \\frac{Count(w, y)}{Count(y)}, \\ \\ where\n",
        "\\tag{4} \\\\\n",
        " Count(w, y) &= \\text{total number of occurrence of $w$ in all SMS messages of category } y \\\\\n",
        "Count(y) &= \\text{total number of words appearing in SMS messages of category } y.\n",
        "\\end{align}\n",
        "\n",
        "*Remark 1:* If $w$ appears in a single message for 3 times, then it contributes to $Count(w, y)$ by 3, not 1. Similarly, $Count(y)$ indeed equals the total length of all messages in category $y$.\n",
        "\n",
        "*Remark 2:* Obviously, the right-hand side of Eq (4) does not depend on $i$. This is consistent with our previous note that we carry the subscript $i$ in $P(X_i|Y)$ only for clarity, while in fact different $i$ share the same $P(X_i|Y)$.\n",
        "\n",
        "For example, suppose there are four messages\n",
        "$$\n",
        "\\text{{'cat is cute', ham}, {'dog rocks', spam}, {'whatever is is right', ham}, {'hello', spam}.}\n",
        "$$\n",
        "Then $P(X_i = '\\text{is}' | \\text{ham}) = 3 / 7$ (**not** $2/7$),\n",
        "and $P(X_i = '\\text{is}' | \\text{spam}) = 0 / 3$.\n",
        "\n",
        "You may have noticed that any word $w$ with $Count(w,y)=0$ leads to $P(X_i = w|Y=y) = 0$.\n",
        "As a result, by Eq (2), any message $x$ has conditional probably $P(X = x |Y=y) = 0$ if $w$ appears in $x$.\n",
        "Such a \"veto\" is not favorable, and can create significant problems when a word in the test data has never appeared in the training data.\n",
        "To bypass this issue, we can add pseudo-count, a.k.a additive smoothing:\n",
        "$$\n",
        "\\hat{P}(X_i = w|Y=y) = \\frac{Count(w, y) + \\alpha}{Count(y) + N\\alpha}, \\tag{5}\n",
        "$$\n",
        "where $\\alpha$ is a smoothing parameter. $\\alpha=0$ corresponds to no smoothing. In our experiment, let us set $\\alpha = 1.0$. $N$ denotes the number of distinct words in the vocabulary, and let us set $N = 20,000$ in this lab.\n",
        "\n",
        "Now Let's start with data preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqrY7MaJ6PrA"
      },
      "outputs": [],
      "source": [
        "# set up code for this experiment\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8VYKq9-6PrP"
      },
      "source": [
        "### 1. Data Preprocessing\n",
        "\n",
        "We will use `pandas` to import the dataset. Since `SMSSpamCollection` separates labels and text content in each message by a tab, we will use '\\t' as the value for the `sep` argument and read raw data into a pandas dataframe. As a result, we store labels and SMS messages into two columns. To facilitate the subsequent steps, we also rename the columns by passing a list `['label', 'sms_message']` to the `names` argument of the `read_table()` method.\n",
        "\n",
        "Let us print the first five rows of the dataframe to get a basic understanding of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXBuWAZ06PrQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ee1ab0a0-f157-4e38-8d21-9800c3b16b39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                        sms_message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f47355c4-ad88-4595-88a7-d6e93b00691d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f47355c4-ad88-4595-88a7-d6e93b00691d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f47355c4-ad88-4595-88a7-d6e93b00691d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f47355c4-ad88-4595-88a7-d6e93b00691d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-27a8ac90-3cea-4ac1-a271-a9e1d57697d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27a8ac90-3cea-4ac1-a271-a9e1d57697d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-27a8ac90-3cea-4ac1-a271-a9e1d57697d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sms_message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Download the dataset to the server\n",
        "# Import the data using the read_csv() method from pandas\n",
        "\n",
        "import urllib.request\n",
        "import shutil\n",
        "\n",
        "url = 'https://www.cs.uic.edu/~zhangx/teaching/SMSSpamCollection.dat'\n",
        "file_name = 'SMSSpamCollection.dat'\n",
        "with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:\n",
        "    shutil.copyfileobj(response, out_file)\n",
        "\n",
        "df = pd.read_csv(file_name,\n",
        "                    sep='\\t',\n",
        "                    header=None,\n",
        "                    names=['label', 'sms_message'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzzbwM0h6Prc"
      },
      "source": [
        "#### Step 1: Convert string labels to numerical labels\n",
        "\n",
        "As we can see, there are 2 columns. The first column, which is named `label`, takes two values `spam` (the message is spam) and `ham` (the message is not spam). The second column is the text content of the SMS message that is being classified.  It is a string in which words are separated by space.\n",
        "\n",
        "Note that the string-typed labels are unwieldy for calculating performance metrices, e.g., when calculating precision and recall scores. Hence, let's convert the lables to binary variables, 0 for `ham` and 1 for `spam`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5myRuvh6Prd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "038b476b-8dcb-4760-e2f4-7110aa06702d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                        sms_message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9def931-e027-44e8-af44-8af6aa335e69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9def931-e027-44e8-af44-8af6aa335e69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9def931-e027-44e8-af44-8af6aa335e69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9def931-e027-44e8-af44-8af6aa335e69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ee94d12-45a6-41d1-8fe5-c2f18d7f1906\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ee94d12-45a6-41d1-8fe5-c2f18d7f1906')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ee94d12-45a6-41d1-8fe5-c2f18d7f1906 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sms_message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Qsp7_C6Prg"
      },
      "source": [
        "#### Step 2: Word sequence\n",
        "\n",
        "What we have in our dataset is a large collection of text data (5,572 rows/messages). Most ML algorithms rely on numerical data to be fed into them as input, but SMS messages are usually text heavy.\n",
        "\n",
        "To address this issue, we use word sequence (BoW), which is designed for problems with a 'word sequence' or a collection of text data. The basic idea is to count the frequency of the words in the text. It is important to note that BoW treats each word individually, ignoring the order in which the words occur.\n",
        "\n",
        "To count the frequency of the words in text, usually we need to process the input text data in four steps:\n",
        "\n",
        "- Convert all strings into their lower case form\n",
        "- Removing all punctuations\n",
        "- Tokenization, i.e., split a sentence into individual words\n",
        "- Count frequencies\n",
        "\n",
        "Once this has been done, we are supposed to obtain a vocabulary dictionary with frequencies of each words for the given text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf3M2dHK6Pri",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1499e091-f5a2-4e88-e9ff-6cfc73f045ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'hello': 3, 'you': 2, 'win': 2, 'call': 2, 'how': 1, 'are': 1, 'money': 1, 'from': 1, 'home': 1, 'me': 1, 'now': 1, 'tomorrow': 1})\n"
          ]
        }
      ],
      "source": [
        "def count_frequency(documents):\n",
        "    \"\"\"\n",
        "    count occurrence of each word in the document set.\n",
        "    Inputs:\n",
        "    - documents: list, each entity is a string type SMS message\n",
        "    Outputs:\n",
        "    - frequency: a dictionary. The key is the unique words, and the value is the number of occurrences of the word\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: covert all strings into their lower case form\n",
        "    lower_case_doc = []\n",
        "    for s in documents:\n",
        "        lower_case_doc.append(s.lower())\n",
        "\n",
        "    # Step 2: remove all punctuations\n",
        "    no_punc_doc = []\n",
        "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    for s in lower_case_doc:\n",
        "        puncfree = ''\n",
        "        for i in s:\n",
        "          if i not in punc:\n",
        "            puncfree += i\n",
        "        no_punc_doc.append(puncfree)\n",
        "\n",
        "    # Step 3: tokenize a sentence, i.e., split a sentence into individual words\n",
        "    # using a delimiter. The delimiter specifies what character we will use to identify the beginning\n",
        "    # and the end of a word.\n",
        "    words_doc = []\n",
        "    for s in no_punc_doc:\n",
        "        words_doc.append(s.split(' '))\n",
        "\n",
        "    # Step 4: count frequencies. To count the occurrence of each word in the document set.\n",
        "    # We can use the `Counter` method from the Python `collections` library for this purpose.\n",
        "    # `Counter` counts the occurrence of each item in the list and returns a dictionary with\n",
        "    # the key as the item being counted and the corresponding value being the count of that item in the list.\n",
        "\n",
        "    all_words = []\n",
        "    for s in words_doc:\n",
        "        all_words.extend(s)\n",
        "    frequency = Counter(all_words)\n",
        "\n",
        "    return frequency\n",
        "\n",
        "# Unit test case:\n",
        "documents = ['Hello, how are you!',\n",
        "            'Win money, win from home.',\n",
        "            'Call me now.',\n",
        "            'Hello, Call hello you tomorrow?']\n",
        "\n",
        "freq = count_frequency(documents)\n",
        "print(freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ5l72qQ6Prn"
      },
      "source": [
        "#### Step 3: Create training and test sets\n",
        "\n",
        "We will partition the `SMSSpamCollection` dataset into training and test sets so that we can analyze the model's performance on data it has not witnessed during training. We'll use its `train_test_split()` method from the `scikit` library to create training and testing sets. In this experiment, we use 80% data for training and the remaining 20% data for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXkkpzP46Pro",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d25027-1d0a-406e-9cf6-98cd6d7e4cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original dataset contains 5572 examples in total.\n",
            "The training set contains 4457 examples.\n",
            "The testing set contains 1115 examples.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], df['label'], test_size=0.2, random_state=1)\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "print(f'The original dataset contains {df.shape[0]} examples in total.')\n",
        "print(f'The training set contains {X_train.shape[0]} examples.')\n",
        "print(f'The testing set contains {X_test.shape[0]} examples.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVB4Giy56Prv"
      },
      "source": [
        "###2. Implementing Naive Bayes method from scratch\n",
        "\n",
        "#### Step 1: training the Naive Bayes Model\n",
        "\n",
        "Now that we know what Naive Bayes is, we can take a closer look at how to calculate the posterior probability\n",
        "$$\n",
        "P(Y|X) \\propto P(Y)\\prod_{i=1}^T P(X_i|Y).\n",
        "$$\n",
        "\n",
        "The goal of training is to learn the prior and conditional probability from data. The calculation of the prior $P(Y=y)$ is straightforward. It can be estimated via the frequency of messages in the training set that belong to class $y$, e.g.,\n",
        "$$\n",
        "P(Y=spam) = \\frac{\\# \\text{training messages in the spam category}}{\\# \\text{training messages}}.\n",
        "$$\n",
        "\n",
        "The conditional probability given the class label --- $P(X_i|Y)$ --- can also be estimated from the data by using Eq (5). As we assumed above, it is indeed independent of $i$ (i.e., shared by all $i$).\n",
        "\n",
        "$$\n",
        "\\hat{P}(X_i = w|Y=y) = \\frac{Count(w, y) + \\alpha}{Count(y) + N\\alpha}, \\tag{5}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CATiEZSw6Prw",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7323a176-be0c-4155-9210-19ad033d2844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.5, 1: 0.5}\n",
            "{0: {'hello': 0.0001999100404817832, 'how': 9.99550202408916e-05, 'are': 9.99550202408916e-05, 'you': 0.0001499325303613374, 'call': 9.99550202408916e-05, 'tomorrow': 9.99550202408916e-05, 'dummy': 4.99775101204458e-05}, 1: {'win': 0.00014994002399040384, 'money': 9.996001599360256e-05, 'from': 9.996001599360256e-05, 'home': 9.996001599360256e-05, 'call': 9.996001599360256e-05, 'me': 9.996001599360256e-05, 'now': 9.996001599360256e-05, 'dummy': 4.998000799680128e-05}}\n"
          ]
        }
      ],
      "source": [
        "def train_NB_model(X_train, y_train):\n",
        "    \"\"\"\n",
        "    training a naive bayes model from the training data.\n",
        "    Inputs:\n",
        "    - X_train: an array of shape (num_train,) which stores SMS messages. each entity is a string type SMS message\n",
        "    - y_train: an array of shape (num_train,). the ground true label for each training data.\n",
        "    Output:\n",
        "    - prior: a dictionary, whose key is the class label, and value is the prior probability.\n",
        "    - conditional: a dictionary whose key is the class label y, and value is another dictionary.\n",
        "                   In the latter dictionary, the key is word w, and the value is the\n",
        "                   conditional probability P(X_i = w | y).\n",
        "    \"\"\"\n",
        "\n",
        "    # compute the prior probability\n",
        "    prior = prior_prob(y_train)\n",
        "\n",
        "    # compute the conditional probability\n",
        "    conditional = conditional_prob(X_train, y_train)\n",
        "\n",
        "    return prior, conditional\n",
        "\n",
        "# Start the auxiliary functions\n",
        "def add_smooth(count_x, count_all, alpha=1.0, N=20000):\n",
        "\n",
        "    \"\"\"\n",
        "    compute the conditional probability for a specific word\n",
        "    Inputs:\n",
        "    - count_x: the number of occurrence of the word\n",
        "    - count_all: the total number of words\n",
        "    - alpha: smoothing parameter\n",
        "    - N: the number of different values of feature x\n",
        "    Outputs:\n",
        "    - prob: conditional probability\n",
        "    \"\"\"\n",
        "    return (count_x + alpha) / (count_all + N*alpha)\n",
        "\n",
        "\n",
        "def prior_prob(y_train):\n",
        "    \"\"\"\n",
        "    compute the prior probability\n",
        "    Inputs:\n",
        "    - y_train: an array that stores ground true label for training data\n",
        "    Outputs:\n",
        "    - prior: a dictionary. key is the class label, value is the prior probability.\n",
        "    \"\"\"\n",
        "\n",
        "    prior = dict(Counter(y_train))\n",
        "    totalCount = sum(prior.values())\n",
        "    prior[0] = prior[0] / totalCount\n",
        "    prior[1] = prior[1] / totalCount\n",
        "\n",
        "    return prior\n",
        "\n",
        "def conditional_prob(X_train, y_train):\n",
        "    \"\"\"\n",
        "    compute the conditional probability for a document set\n",
        "    Inputs:\n",
        "    - X_train: an array of shape (num_train,) which stores SMS messages. each entity is a string type SMS message\n",
        "    - y_train: an array of shape (num_train,). the ground true label for each training data.\n",
        "    Ouputs:\n",
        "    - cond_prob: a dictionary. key is the class label, value is a dictionary in which the key is word, the value is the conditional probability of feature x_i given y.\n",
        "    \"\"\"\n",
        "\n",
        "    num_train = X_train.shape[0]\n",
        "\n",
        "    ham_data = []\n",
        "    spam_data = []\n",
        "\n",
        "    for s in range(num_train): #populating spam and ham lists\n",
        "      if y_train[s] == 0:\n",
        "        ham_data.append(X_train[s])\n",
        "      else:\n",
        "        spam_data.append(X_train[s])\n",
        "\n",
        "    freq_spam = dict(count_frequency(spam_data)) #spam dictionary where key is word and value is number of occurrences of that word [count(w,y=spam)]\n",
        "    count_spam = sum(freq_spam.values()) #sum of word counts in spam category [count(y=spam)]\n",
        "    freq_ham = dict(count_frequency(ham_data))\n",
        "    count_ham = sum(freq_ham.values())\n",
        "\n",
        "    for word in freq_spam.keys(): #populating spam dictionary with smoothed conditional probabilities for each spam word [P(X|Y=spam)]\n",
        "      freq_spam[word] = add_smooth(freq_spam[word], count_spam)\n",
        "\n",
        "    for word in freq_ham.keys():\n",
        "      freq_ham[word] = add_smooth(freq_ham[word], count_ham)\n",
        "\n",
        "    #computing conditional probability for unseen words:\n",
        "    freq_spam['dummy'] = add_smooth(0, count_spam)\n",
        "    freq_ham['dummy'] = add_smooth(0, count_ham)\n",
        "\n",
        "    cond_prob = dict()\n",
        "    cond_prob[0] = freq_ham\n",
        "    cond_prob[1] = freq_spam\n",
        "\n",
        "    return cond_prob\n",
        "\n",
        "# unit test case:\n",
        "x_train = np.array(['Hello, how are you!',\n",
        "            'Win money, win from home.',\n",
        "            'Call me now.',\n",
        "            'Hello, Call hello you tomorrow?'])\n",
        "y_train_mini = np.array([0,1,1,0])\n",
        "\n",
        "prior = prior_prob(y_train_mini)\n",
        "cond_prob = conditional_prob(x_train, y_train_mini)\n",
        "print(prior)\n",
        "print(cond_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdPoLF0-6Pr2"
      },
      "source": [
        "#### Step 2: predict label for test data\n",
        "\n",
        "Once we have the two models $P(Y)$ and $P(X_i|Y)$ from *training*, we can use them to predict the label for a given test message. To this end, we need to compute the probability of all possible labels, and then predict the one with maximum probability value:\n",
        "$$\n",
        "\\arg\\max_Y P(Y)\\prod_{i=1}^T P(X_i|Y). \\tag{6}\n",
        "$$\n",
        "\n",
        "**Avoid numerical underflow with log-trick.**\n",
        "As shown in the above equation, the calculation involves multiplying many probabilities together. Since probabilities lie in $(0,1]$, multiplying many of them together can lead to numerical underflow (i.e., a floating point number close to 0 gets rounded down to 0 by a computer), especially when $T$ is large, i.e., the test message is long.\n",
        "\n",
        "To overcome this problem, it is common to change the calculation from the product of probabilities to the sum of log probabilities.\n",
        "That is, take the natual logarithm of the right-hand side of Eq (6) as\n",
        "$$\n",
        "g_Y(X) = \\log P(Y) + \\sum_{i=1}^T \\log P(X_i|Y). \\tag{7}\n",
        "$$\n",
        "It is much more numerically stable to compute $g_Y(X)$ and to take $\\arg\\max_Y g_Y(X)$ to find the most likely class label (as the output prediction).\n",
        "\n",
        "With $g_Y(X)$, we can easily compute the posterior probability by\n",
        "$$\n",
        "P(Y|X) = \\frac{\\exp (g_Y(X) - m)}{\\sum_y \\exp (g_y(X)-m)},\n",
        "\\text{ where  }\n",
        "m = \\max_y g_y(X).\n",
        "$$\n",
        "In our message classification problem, the summation in the denominator is just over `positive` and `negative`.\n",
        "Note we subtract by $m$, which does not change the result because the numerator and denominator cancel.\n",
        "However it is numerically useful because sometimes all $g_Y(X)$ are overly small and can cause numerical underflow inside exponentiation.\n",
        "By subtracting $m$, $g_Y(X) - m$ will be 0 (properly scaled) for at least one value of $Y$, and be negative for the other.  And even if another $y$ still suffers underflow in exponentiating $g_y(X)-m$, the posterior probabilities will still be correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iDZ9QpB6Pr4",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fa28e4-ca68-4ad3-8f1b-3182fe056ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] [[0.97958684 0.02041316]]\n"
          ]
        }
      ],
      "source": [
        "from scipy.special import softmax\n",
        "def predict_label(X_test, prior_prob, cond_prob):\n",
        "    \"\"\"\n",
        "    predict the class labels for the testing set\n",
        "    Inputs:\n",
        "    - X_test: an array of shape (num_test,) which stores test data.\n",
        "              Each entity is a string type SMS message.\n",
        "    - prior_prob: a dictionary which stores the prior probability for all categories\n",
        "              We previously used \"prior_prob\" as the name of function.\n",
        "              Here it is used as a dictionary name.  No confusion should arise.\n",
        "    - cond_prob: a dictionary whose key is the class label y, and value is another dictionary.\n",
        "                   In the latter dictionary, the key is word w, and the value is the\n",
        "                   conditional probability P(X_i = w | y).\n",
        "    Outputs:\n",
        "    - predict: an array that stores predicted labels\n",
        "    - test_prob: an array of shape (num_test, num_classes) which stores the posterior probability of each class\n",
        "    \"\"\"\n",
        "\n",
        "    num_test = X_test.shape[0]\n",
        "    num_classes = len(cond_prob.keys())\n",
        "    predict = np.empty(num_test)\n",
        "    test_prob = np.empty((num_test, num_classes))\n",
        "\n",
        "    for i in range(num_test):\n",
        "      punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "      clean = ''\n",
        "      for char in X_test[i]:\n",
        "         if char not in punc:\n",
        "            clean += char\n",
        "      word_count = Counter(clean.lower().split()) #first arg in compute_test_prob\n",
        "      for j in range(num_classes):\n",
        "        test_prob[i,j] = compute_test_prob(word_count, prior_prob[j], cond_prob[j])\n",
        "      m = np.max(test_prob[i])\n",
        "      test_prob[i] = softmax(test_prob[i]-m)\n",
        "\n",
        "    predict = np.argmax(test_prob, axis=1)\n",
        "\n",
        "    return predict, test_prob\n",
        "\n",
        "def compute_test_prob(word_count, prior_cat, cond_cat):\n",
        "    \"\"\"\n",
        "    predict the discriminant value g_y of a specific category for one test example\n",
        "    Inputs:\n",
        "    - word_count: a dictionary which stores the frequencies of each word in a SMS message.\n",
        "                  Key is the word, value is the number of its occurrence in that message\n",
        "    - prior_cat: a scalar. prior probability of a specific category\n",
        "    - cond_cat: a dictionary. conditional probability of a specific category\n",
        "    Outputs:\n",
        "    - prob: discriminant value g_y of a specific category for the test example\n",
        "                  (no need of normalization, i.e., not exactly the posterior probability)\n",
        "    \"\"\"\n",
        "\n",
        "    prob = np.log(prior_cat)\n",
        "\n",
        "    for word in word_count.keys():\n",
        "      if word not in cond_cat.keys():\n",
        "        prob += word_count[word]*np.log(cond_cat['dummy'])\n",
        "      else:\n",
        "        prob += word_count[word]*np.log(cond_cat[word])\n",
        "\n",
        "    return prob\n",
        "\n",
        "# unit test case:\n",
        "x_test = np.array(['Hello, how are you today!'])\n",
        "y_pred, test_prob = predict_label(x_test, prior, cond_prob)\n",
        "print(y_pred, test_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QINYf3KB6Pr-"
      },
      "source": [
        "#### Step 3: compute performance metrics\n",
        "You may have noticed that the classes are heavily imbalanced. There are only 747 `spam` messages, compared with 4827 `ham` messages. If a classifier simply predicts all messages as `ham`, it will get around 86% accuracy (pretty high). Therefore, accuracy is not a good metric in this case for evaluating the performance of the classifier. Instead, we can use F-score metrics using the builtin methods from `scikit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb58oHwb6PsA",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c12a9d-e095-4f14-aca0-655879bca0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5 [[1 2]\n",
            " [1 2]] 0.5714285714285715\n"
          ]
        }
      ],
      "source": [
        "def compute_metrics(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    compute the performance metrics\n",
        "    Inputs:\n",
        "    - y_pred: an array of predictions\n",
        "    - y_true: an array of ground true labels\n",
        "    Outputs:\n",
        "    - acc: accuracy\n",
        "    - cm: confusion matrix\n",
        "    - f1: f1_score\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    return acc, cm, f1\n",
        "\n",
        "# unit test case:\n",
        "y_pred = np.array([0,1,1,1,0,1])\n",
        "y_true = np.array([0,1,0,0,1,1])\n",
        "acc, cm, f1 = compute_metrics(y_pred, y_true)\n",
        "print(acc, cm, f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZLTG_uros32"
      },
      "source": [
        "#### Step 4: Plot ROC curve and print other results\n",
        "\n",
        "ROC (Receiver Operating Characteristics) curve is one of the most commonly used metrics for evaluating the performance of machine learning algorithms, especially when the classes are imbalanced.\n",
        "\n",
        "ROC is a probability curve for different classes. ROC tells us how good the model is for distinguishing the given classes, in term of the **predicted probability** (not the final hard label in pos/neg). A typical ROC curve has False Positive Rate (FPR) on the $x$-axis and True Positive Rate (TPR) on the $y$-axis. To obtain the FPR and TPR, we can use the `roc_curve` method from `scikit`. This `roc_curve` function takes two arguments: 1) the ground truth labels of the test examples, and 2) the predicted probability that each example is positive. It returns the FPR and TPR which can be used for plotting.\n",
        "\n",
        "We can even compute the area under the curve (AUC) by calling `roc_auc_score` which takes the same arguments as `roc_curve` required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DiYOIdIo7F7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "9745bcd1-afc0-4ae7-f7ca-8005f48ba508"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9820093326586833 0.9874439461883409 [[965   3]\n",
            " [ 11 136]] 0.951048951048951\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "def plot_roc_curve(fpr, tpr):\n",
        "  plt.plot(fpr, tpr, color='blue', label='ROC')\n",
        "  plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
        "  plt.xlabel('FPR')\n",
        "  plt.ylabel('TPR')\n",
        "  plt.title('ROC Curve')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# We now compute the test performance.\n",
        "# X_train, X_test, y_train, y_test are the same as above\n",
        "\n",
        "# training naive Bayes model\n",
        "prior, cond = train_NB_model(X_train, y_train)\n",
        "\n",
        "\n",
        "# evaluate on test set\n",
        "y_pred, prob = predict_label(X_test, prior, cond)\n",
        "\n",
        "y_score = prob[:,1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_score)\n",
        "\n",
        "plot_roc_curve(fpr,tpr)\n",
        "\n",
        "acc, cm, f1 = compute_metrics(y_pred, y_test)\n",
        "\n",
        "print(auc,acc,cm,f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit ('base': conda)",
      "name": "python_defaultSpec_1600651579462"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}